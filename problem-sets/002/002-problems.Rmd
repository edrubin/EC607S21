---
title: "002: Regression and matching"
subtitle: "EC 607"
# author: "Edward Rubin"
date: "Due *before* midnight on Wednesday, 19 May 2021"
output:
  xaringan::moon_reader:
    css: ['default', 'metropolis', 'metropolis-fonts', 'my-css.css']
    # self_contained: true
    nature:
      ratio: '8.5:11'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---
class: clear

```{r, setup, include = F}
# Packages
library(pacman)
p_load(
  ggplot2, gridExtra, ggthemes, latex2exp, kableExtra,
  tidyverse, broom, knitr, magrittr
)
# Colors
red_pink <- "#e64173"
turquoise <- "#20B2AA"
grey_light <- "grey70"
grey_mid <- "grey50"
grey_dark <- "grey20"
# Knitr options
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  warning = F,
  message = F
)
```

.mono.b[DUE] Your solutions to this problem set are due *before* 11:59pm on Wednesday, 19 May 2021 on [Canvas](https://canvas.uoregon.edu/).

Your problem set .hi[must be typed] with .mono[R] code beneath your responses. _E.g._,  [`knitr`](https://yihui.name/knitr/) and [`R Markdown`](https://rmarkdown.rstudio.com).

.mono.b[OBJECTIVE] This problem set has three purposes: (1) reinforce the econometrics topics we reviewed in class; (2) build your .mono[R] toolset; (3) start building your intuition about causality within econometrics.

.mono.b[README] This problem set uses data from [LaLonde (1986)](https://www.jstor.org/stable/1806062), who compared the estimated effects of a randomized employment program—National Supported Work Demonstration (NSW)—to the estimated effects produced using non-experimental methods (_i.e._, pretending treatment had not been randomized). You should read (at least the first few pages of) the paper. More [here](https://www.mitpressjournals.org/doi/pdf/10.1162/003465302317331982) from Dehejia and Wahba (2002).

.mono.b[01.] Download and load two datasets: (1) [data from the randomized employment program](http://users.nber.org/~rdehejia/data/nsw.dta) (we'll call this the .b[NSW data]) and (2) [data on 2,490 potential 'control' individuals from the PSID (Panel Study of Income Dynamics)](http://users.nber.org/~rdehejia/data/psid_controls.dta) (we'll call this the .b[PSID data]).

```{r, key-01, include = F}
# Load packages
library(pacman)
p_load(tidyverse, haven, estimatr, magrittr)
# Load LaLonde's experimental data
nsw_df <- read_dta("http://users.nber.org/~rdehejia/data/nsw.dta")
# Load PSID potential controls
psid_df <- read_dta("http://users.nber.org/~rdehejia/data/psid_controls.dta")
```
The last page of the problem set describes the variables in these data.

.hi-pink[Note] .b[Questions .mono[02–07] use the .it[NSW data].]

.mono.b[02.] Regress real earnings in 1975 (the year before treatment) on treatment (and an intercept, which we will always assume should be included unless otherwise stated). Why/how is this regression (and its outcome) informative? What does it tell us?

```{r, key-02, include = F}
lm_robust(re75 ~ treat, data = nsw_df)
```

.mono.b[03.] The program rolled out in 1976 and ended (at least for our purposes) in 1978, so we'll use earnings in 1978 to estimate whether the program had any sustained effect on earnings.

Regress 1978 earnings on treatment. What do you find?

```{r, key-03, include = F}
lm_robust(re78 ~ treat, data = nsw_df)
```

.mono.b[04.] What is required for us to interpret the estimated in .mono.b[03.] as causal? Does our setting meet this requirement?

.mono.b[05.] Add controls for age, education (level and degree), race (black and Hispanic), and marital status. How does your estimated treatment effect and its standard change. Why do you think this happense?

```{r, key-05, include = F}
lm_robust(re78 ~ treat + age + education + black + hispanic + married + nodegree, data = nsw_df)
```

.mono.b[06.] What is a "bad control"? Are any of the controls we added in .mono.b[05.] "bad"? Briefly explain.

.mono.b[07.] Since we have an experiment, can we interpret the coefficient on .mono[nodegree] (not having a high-school diploma) as causal? What about its interaction with treatment? Briefly explain.

.mono.b[08.] Compare a simple difference in means to your results in the regression results in .mono.b[03.].

.it[Hint] The `dplyr` functions `group_by()` and `summarize()` could be helpful.

```{r, key-08, include = F}
nsw_df %>% group_by(treat) %>% summarize(mean(re78))
```

.mono.b[09.] Create a new dataset that combines .b[treated individuals from the .it[NSW data]] and .b[control individuals from the .it[PSID data]]. We'll refer to this dataset as our .b[mixed dataset].

.it[Hint] Remember our old friends `filter()` and `bind_rows()` from `dplyr`.

```{r, key-09, include = F}
mixed_df <- bind_rows(
  filter(nsw_df, treat == 1),
  psid_df
)
```

.hi-pink[Note] .b[Questions from .mono[10–13] use this .it[mixed dataset]], focusing on earnings in 1978.

.mono.b[10.] Compare the difference in means from the .b[mixed dataset] to the difference from the .b[NSW dataset].

.mono.b[11.] Use our potential-outcomes (Rubin causal model) notation to explain how the difference with the mixed dataset may be biased. Does the sign of the difference across the two differences-in-means match what you would expect from our model of selection bias? Briefly explain.

---
class: clear

.mono.b[12.] Time for nearest-neighbor matching. Use all six covariates. **You must write write the code for this matching yourself.** You *can* use basic pre-written functions (*e.g.*, `mean`), but do not use matching-estimation packages that do all of the matching for you.

.move-right[
.mono.b[12A.] Estimate the average treatment effect on the treated by matching treated individuals to their nearest neighbor using a .b[Euclidean] metric.
]

.move-right[
.mono.b[12B.] Estimate the average treatment effect on the treated by matching treated individuals to their nearest neighbor using a .b[Mahalanobis] metric. *Hint:* The `StatMatch` package has a function named `mahalanobis.dist()` that finds the *Mahalanobis distance* between observations of two datasets.
]

.move-right[
.mono.b[12C.] How do your estimates in .mono.b[12A.] and .mono.b[12B.] compare to your previous estimates?

]

.move-right[
.b[Extra credit] Use kernel matching (any kernel) to estimate the treatment effect.
]

.move-right[]

.mono.b[13.] Now for propensity-score methods. **Again: Do not use pre-written propensity-score packages. Write the code for the steps.** You *can* use the `glm()` function to estimate a logit regression (more below in .mono.b[13A]).

.move-right[
.mono.b[13A.] Estimate the propensity score for each treated individual using the covariates using a logit model that is linear in the covariates. Which variables are predictive of treatment?

.it[Hint:] The function `glm()` with `family = binomial` estimates a logit model.

```{r, key-13a, include = F}
# Estimate logit model for propensity scores, linear in covariates
pscore_logit <- glm(treat ~ age + education + black + hispanic + married + nodegree, data = mixed_df)
```
]

.move-right[
.mono.b[13B.] Add the estimated propensity scores $\left(\widehat{p}_{i}\right)$ to the mixed dataset. Is there overlap? Explain.

.it[Hint:] You can access predictions from a model using `$fitted.values`.
<br>.it[Another hint:] Try histograms grouped/filled by treatment status.

```{r, key-13b, include = F}
# Add propensity scores
mixed_df$p_score <- pscore_logit$fitted.values
```
]

.move-right[
.mono.b[13C.] Enforce overlap using the minimum $\widehat{p}_i$ observed in the treated group and the maximum $\widehat{p}_i$ observed in the control group.
]

.move-right[
.mono.b[13D.] Estimate the treatment effect using a regression that conditions on $\widehat{p}_i$. What happens if you also include $\widehat{p}_i$ interacted with treatment?
]

.move-right[
.mono.b[13E.] Now estimate the treatment effect by blocking on $\widehat{p}_i$.
]

.move-right[
.b[Extra credit] Use the *doubly robust method* that combines regression and blocking.
]

.mono.b[14.] Draw a DAG for this setting. Compare the various treatment effects that you've estimated in .mono.b[10–13]. How do they compare to the effects you estimated .mono.b[03.]? Which controls does your DAG suggest? (Explain.) Which estimates should we trust? Why?  

---
class: clear

## Data description

<br>

```{r, background variables, echo = F, eval = T}
var_tbl <- data.frame(
  Variable = names(psid_df) %>% paste0(".mono[", ., "]"),
  Description = c(
    "Dataset identifier.",
    "Treatment indicator (select to be part of NSW).",
    "Age (years).",
    "Education (years).",
    "Indicator for whether the individual is black.",
    "Indicator for whether the individual is Hispanic.",
    "Indicator for whether the individual is married.",
    "Indicator for individuals without a high-school diploma.",
    "Real earnings in 1974 (1982 dollars).",
    "Real earnings in 1975 (1982 dollars).",
    "Real earnings in 1978 (1982 dollars)."
  )
)
kable(var_tbl) %>%
  kable_styling(full_width = F)
```

.b[Note:] The NSW dataset does not include .mono[re74].

```{r, generate pdfs, include = F, eval = F}
pagedown::chrome_print(input = "002-problems.html")
```